{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras-DCGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moustafa-7/Car-GANs_project/blob/master/Keras_DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB9UrNxSci5y",
        "colab_type": "code",
        "outputId": "31f77863-8635-4a68-bb1f-16f02d73646b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/Maximellerbach/Car-DCGAN-Keras.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Car-DCGAN-Keras'...\n",
            "remote: Enumerating objects: 530, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/530)\u001b[K\rremote: Counting objects:   1% (6/530)\u001b[K\rremote: Counting objects:   2% (11/530)\u001b[K\rremote: Counting objects:   3% (16/530)\u001b[K\rremote: Counting objects:   4% (22/530)\u001b[K\rremote: Counting objects:   5% (27/530)\u001b[K\rremote: Counting objects:   6% (32/530)\u001b[K\rremote: Counting objects:   7% (38/530)\u001b[K\rremote: Counting objects:   8% (43/530)\u001b[K\rremote: Counting objects:   9% (48/530)\u001b[K\rremote: Counting objects:  10% (53/530)\u001b[K\rremote: Counting objects:  11% (59/530)\u001b[K\rremote: Counting objects:  12% (64/530)\u001b[K\rremote: Counting objects:  13% (69/530)\u001b[K\rremote: Counting objects:  14% (75/530)\u001b[K\rremote: Counting objects:  15% (80/530)\u001b[K\rremote: Counting objects:  16% (85/530)\u001b[K\rremote: Counting objects:  17% (91/530)\u001b[K\rremote: Counting objects:  18% (96/530)\u001b[K\rremote: Counting objects:  19% (101/530)\u001b[K\rremote: Counting objects:  20% (106/530)\u001b[K\rremote: Counting objects:  21% (112/530)\u001b[K\rremote: Counting objects:  22% (117/530)\u001b[K\rremote: Counting objects:  23% (122/530)\u001b[K\rremote: Counting objects:  24% (128/530)\u001b[K\rremote: Counting objects:  25% (133/530)\u001b[K\rremote: Counting objects:  26% (138/530)\u001b[K\rremote: Counting objects:  27% (144/530)\u001b[K\rremote: Counting objects:  28% (149/530)\u001b[K\rremote: Counting objects:  29% (154/530)\u001b[K\rremote: Counting objects:  30% (159/530)\u001b[K\rremote: Counting objects:  31% (165/530)\u001b[K\rremote: Counting objects:  32% (170/530)\u001b[K\rremote: Counting objects:  33% (175/530)\u001b[K\rremote: Counting objects:  34% (181/530)\u001b[K\rremote: Counting objects:  35% (186/530)\u001b[K\rremote: Counting objects:  36% (191/530)\u001b[K\rremote: Counting objects:  37% (197/530)\u001b[K\rremote: Counting objects:  38% (202/530)\u001b[K\rremote: Counting objects:  39% (207/530)\u001b[K\rremote: Counting objects:  40% (212/530)\u001b[K\rremote: Counting objects:  41% (218/530)\u001b[K\rremote: Counting objects:  42% (223/530)\u001b[K\rremote: Counting objects:  43% (228/530)\u001b[K\rremote: Counting objects:  44% (234/530)\u001b[K\rremote: Counting objects:  45% (239/530)\u001b[K\rremote: Counting objects:  46% (244/530)\u001b[K\rremote: Counting objects:  47% (250/530)\u001b[K\rremote: Counting objects:  48% (255/530)\u001b[K\rremote: Counting objects:  49% (260/530)\u001b[K\rremote: Counting objects:  50% (265/530)\u001b[K\rremote: Counting objects:  51% (271/530)\u001b[K\rremote: Counting objects:  52% (276/530)\u001b[K\rremote: Counting objects:  53% (281/530)\u001b[K\rremote: Counting objects:  54% (287/530)\u001b[K\rremote: Counting objects:  55% (292/530)\u001b[K\rremote: Counting objects:  56% (297/530)\u001b[K\rremote: Counting objects:  57% (303/530)\u001b[K\rremote: Counting objects:  58% (308/530)\u001b[K\rremote: Counting objects:  59% (313/530)\u001b[K\rremote: Counting objects:  60% (318/530)\u001b[K\rremote: Counting objects:  61% (324/530)\u001b[K\rremote: Counting objects:  62% (329/530)\u001b[K\rremote: Counting objects:  63% (334/530)\u001b[K\rremote: Counting objects:  64% (340/530)\u001b[K\rremote: Counting objects:  65% (345/530)\u001b[K\rremote: Counting objects:  66% (350/530)\u001b[K\rremote: Counting objects:  67% (356/530)\u001b[K\rremote: Counting objects:  68% (361/530)\u001b[K\rremote: Counting objects:  69% (366/530)\u001b[K\rremote: Counting objects:  70% (371/530)\u001b[K\rremote: Counting objects:  71% (377/530)\u001b[K\rremote: Counting objects:  72% (382/530)\u001b[K\rremote: Counting objects:  73% (387/530)\u001b[K\rremote: Counting objects:  74% (393/530)\u001b[K\rremote: Counting objects:  75% (398/530)\u001b[K\rremote: Counting objects:  76% (403/530)\u001b[K\rremote: Counting objects:  77% (409/530)\u001b[K\rremote: Counting objects:  78% (414/530)\u001b[K\rremote: Counting objects:  79% (419/530)\u001b[K\rremote: Counting objects:  80% (424/530)\u001b[K\rremote: Counting objects:  81% (430/530)\u001b[K\rremote: Counting objects:  82% (435/530)\u001b[K\rremote: Counting objects:  83% (440/530)\u001b[K\rremote: Counting objects:  84% (446/530)\u001b[K\rremote: Counting objects:  85% (451/530)\u001b[K\rremote: Counting objects:  86% (456/530)\u001b[K\rremote: Counting objects:  87% (462/530)\u001b[K\rremote: Counting objects:  88% (467/530)\u001b[K\rremote: Counting objects:  89% (472/530)\u001b[K\rremote: Counting objects:  90% (477/530)\u001b[K\rremote: Counting objects:  91% (483/530)\u001b[K\rremote: Counting objects:  92% (488/530)\u001b[K\rremote: Counting objects:  93% (493/530)\u001b[K\rremote: Counting objects:  94% (499/530)\u001b[K\rremote: Counting objects:  95% (504/530)\u001b[K\rremote: Counting objects:  96% (509/530)\u001b[K\rremote: Counting objects:  97% (515/530)\u001b[K\rremote: Counting objects:  98% (520/530)\u001b[K\rremote: Counting objects:  99% (525/530)\u001b[K\rremote: Counting objects: 100% (530/530)\u001b[K\rremote: Counting objects: 100% (530/530), done.\u001b[K\n",
            "remote: Compressing objects: 100% (529/529), done.\u001b[K\n",
            "remote: Total 746 (delta 29), reused 479 (delta 1), pack-reused 216\n",
            "Receiving objects: 100% (746/746), 95.41 MiB | 12.68 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfeKY3XAgYtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"Car-DCGAN-Keras\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnP6ItXUgoyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pycat generate.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_9L1pS4rwJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir('my_imgs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfAZKI4qngBd",
        "colab_type": "code",
        "outputId": "be9cfee2-27d4-4476-ff42-2cef78e5aa0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile generate.py\n",
        "\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import time\n",
        "\n",
        "\n",
        "gen = load_model('vroum//vroumgen.h5')\n",
        "dis = load_model('vroum//vroumdis.h5')\n",
        "\n",
        "\n",
        "while(1):\n",
        "\n",
        "    rand_noise = np.random.normal(0, 1, (1, 100))\n",
        "    pred = gen.predict(rand_noise)\n",
        "    confidence = dis.predict(pred)\n",
        "\n",
        "    gen_img = (0.5 * pred[0] + 0.5)*255\n",
        "\n",
        "    cv2.imwrite(\"my_imgs/\"+str(time.time())+'_'+str(confidence[0][0])+'.png', gen_img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting generate.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJMc6hk3hJLd",
        "colab_type": "code",
        "outputId": "943d387d-37b2-46d4-c292-901b12316ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile gan.py\n",
        "\n",
        "import os\n",
        "import time\n",
        "from glob import glob\n",
        "\n",
        "import cv2\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.layers import (Activation, BatchNormalization, Dense, Dropout,\n",
        "                          Embedding, Flatten, Input, Reshape, ZeroPadding2D,\n",
        "                          multiply)\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import (AveragePooling2D, Conv2D,\n",
        "                                        Conv2DTranspose, MaxPooling2D,\n",
        "                                        UpSampling2D, ZeroPadding2D)\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.optimizers import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class DCGAN():\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.img_rows = 100\n",
        "        self.img_cols = 150\n",
        "        self.channels = 3\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        self.latent_dim = 100\n",
        "\n",
        "\n",
        "        optimizer = Adam(0.0001, 0.5)\n",
        "\n",
        "        '''\n",
        "        # uncomment to build discriminator, generator\n",
        "        \n",
        "        self.discriminator = self.create_discriminator()\n",
        "        self.discriminator.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "        self.generator = self.create_generator()\n",
        "        \n",
        "        '''\n",
        "\n",
        "        # uncomment to load discriminator, generator\n",
        "        self.discriminator = load_model('vroum//vroumdis.h5')\n",
        "        self.discriminator.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "        self.generator = load_model('vroum//vroumgen.h5')\n",
        "        \n",
        "        # the combined model take an image as input and output validity from 0 to 1\n",
        "        # note that in the combined model, the discriminator is not trainable\n",
        "        self.discriminator.trainable = False\n",
        "        \n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        img = self.generator(z)\n",
        "        valid = self.discriminator(img)\n",
        "\n",
        "        self.combined = Model(z, valid) \n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    def create_generator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Dense(6 * 9 * 256, activation=\"relu\", input_dim=self.latent_dim))\n",
        "        model.add(Reshape((6, 9, 256)))\n",
        "\n",
        "        model.add(Conv2D(256, kernel_size=(3,3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(UpSampling2D())\n",
        "        \n",
        "        model.add(Conv2D(128, kernel_size=(3,3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        \n",
        "        model.add(UpSampling2D())\n",
        "\n",
        "        model.add(ZeroPadding2D(padding = ((0,1),(0,1))))\n",
        "\n",
        "        model.add(Conv2D(64, kernel_size=(3,3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(UpSampling2D())\n",
        "\n",
        "        model.add(ZeroPadding2D(padding = (0,(1,0))))\n",
        "\n",
        "        model.add(Conv2D(32, kernel_size=(3,3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(UpSampling2D())\n",
        "\n",
        "        model.add(Conv2D(16, kernel_size=(3,3), padding=\"same\"))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(Conv2D(self.channels, kernel_size=(1,1), padding=\"same\"))\n",
        "        model.add(Activation(\"tanh\"))\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        img = model(noise)\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        return Model(noise, img)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def create_discriminator(self):\n",
        "        \n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(AveragePooling2D())\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(AveragePooling2D())\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        img = Input(shape=self.img_shape)\n",
        "        validity = model(img)\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    \n",
        "\n",
        "    def train(self, batch_size=128, save_interval=50, save_img_interval=50):\n",
        "        \n",
        "        #get dataset\n",
        "        X_train = self.load_dataset('car_img//*')\n",
        "\n",
        "        # ones = label for real images\n",
        "        # zeros = label for fake images\n",
        "        ones = np.ones((batch_size, 1)) \n",
        "        zeros = np.zeros((batch_size, 1))\n",
        "\n",
        "        # create some noise to track AI's progression\n",
        "        self.noise_pred = np.random.normal(0, 1, (1, self.latent_dim))\n",
        "\n",
        "        epoch = 0\n",
        "        while(1):\n",
        "            epoch+=1\n",
        "\n",
        "            # Select a random batch of images in dataset\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            imgs = X_train[idx]\n",
        "\n",
        "            \n",
        "            # Sample noise and generate a batch of new images\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            gen_imgs = self.generator.predict(noise)   \n",
        "\n",
        "            # Train the discriminator with generated images and real images\n",
        "            d_loss_r = self.discriminator.train_on_batch(imgs, ones)\n",
        "            d_loss_f = self.discriminator.train_on_batch(gen_imgs, zeros)\n",
        "            d_loss = np.add(d_loss_r , d_loss_f)*0.5\n",
        "\n",
        "            # Trains the generator to fool the discriminator\n",
        "            g_loss = self.combined.train_on_batch(noise, ones)\n",
        "\n",
        "            #print loss and accuracy of both trains\n",
        "            print (\"%d D loss: %f, acc.: %.2f%% G loss: %f\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "            \n",
        "\n",
        "            if epoch % save_img_interval == 0:\n",
        "                self.save_imgs(epoch)\n",
        "            \n",
        "            if epoch % save_interval == 0:\n",
        "\n",
        "                #self.discriminator.save('gan\\\\vroum\\\\vroumdis_'+str(epoch)+'.h5')\n",
        "                #self.generator.save('gan\\\\vroum\\\\vroumgen_'+str(epoch)+'.h5')\n",
        "\n",
        "                self.discriminator.save('vroum//vroumdis.h5')\n",
        "                self.generator.save('vroum//vroumgen.h5')\n",
        "\n",
        "    def save_imgs(self, epoch):\n",
        "\n",
        "        gen_img = self.generator.predict(self.noise_pred)\n",
        "        confidence = self.discriminator.predict(gen_img)\n",
        "\n",
        "        # Rescale image to 0 - 255\n",
        "        gen_img = (0.5 * gen_img + 0.5)*255\n",
        "\n",
        "        cv2.imwrite('car//%d_%f.png'%(epoch, confidence), gen_img[0])\n",
        "\n",
        "\n",
        "    def load_dataset(self,path):\n",
        "\n",
        "        try:\n",
        "            # try to load existing X_train\n",
        "            X_train = np.load('X_train.npy')\n",
        "            print('loaded dataset')\n",
        "\n",
        "        except:\n",
        "            # else, build X_train and save it\n",
        "            X_train = []\n",
        "            dos = glob(path)\n",
        "\n",
        "            for i in tqdm(dos):\n",
        "                img = cv2.imread(i)\n",
        "                img = cv2.resize(img,(self.img_cols, self.img_rows))\n",
        "\n",
        "                X_train.append(img)\n",
        "\n",
        "            cv2.destroyAllWindows()\n",
        "            X_train = np.array(X_train)\n",
        "\n",
        "            # Rescale dataset to -1 - 1\n",
        "            X_train = X_train / 127.5 - 1\n",
        "\n",
        "            np.save('X_train.npy',X_train)\n",
        "            print('created dataset')\n",
        "            \n",
        "        return X_train\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    cgan = DCGAN()\n",
        "    cgan.train(batch_size=8, save_interval=5000, save_img_interval=25)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting gan.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzrHr-0_hrwB",
        "colab_type": "code",
        "outputId": "449ccdc4-f3f0-4f5d-e74c-6792dcd9aab4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python generate.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0827 01:28:08.131962 139672555734912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0827 01:28:08.166800 139672555734912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0827 01:28:08.233519 139672555734912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0827 01:28:08.233807 139672555734912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0827 01:28:08.234048 139672555734912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2019-08-27 01:28:08.256223: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-08-27 01:28:08.257672: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14b0bc0 executing computations on platform Host. Devices:\n",
            "2019-08-27 01:28:08.257712: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-08-27 01:28:08.262956: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-08-27 01:28:08.401920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-27 01:28:08.404996: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14b0d80 executing computations on platform CUDA. Devices:\n",
            "2019-08-27 01:28:08.405039: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-08-27 01:28:08.406316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-27 01:28:08.407142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-27 01:28:08.417649: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-27 01:28:08.585658: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-27 01:28:08.664715: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-08-27 01:28:08.685994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-08-27 01:28:08.903167: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-08-27 01:28:09.006530: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-08-27 01:28:09.366413: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-08-27 01:28:09.366656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-27 01:28:09.367539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-27 01:28:09.368321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-27 01:28:09.371227: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-08-27 01:28:09.372746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-08-27 01:28:09.372781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-08-27 01:28:09.372799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-08-27 01:28:09.376963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-27 01:28:09.377799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-27 01:28:09.378583: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-08-27 01:28:09.378648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "W0827 01:28:11.611873 139672555734912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0827 01:28:11.690775 139672555734912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n",
            "W0827 01:28:12.467203 139672555734912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "W0827 01:28:12.473440 139672555734912 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0827 01:28:13.501862 139672555734912 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0827 01:28:13.510400 139672555734912 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "  warnings.warn('Error in loading the saved optimizer '\n",
            "2019-08-27 01:28:14.818741: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-08-27 01:28:15.454435: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "Traceback (most recent call last):\n",
            "  File \"generate.py\", line 18, in <module>\n",
            "    confidence = dis.predict(pred)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1169, in predict\n",
            "    steps=steps)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\", line 294, in predict_loop\n",
            "    batch_outs = f(ins_batch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2715, in __call__\n",
            "    return self._call(inputs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2675, in _call\n",
            "    fetched = self._callable_fn(*array_vals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1458, in __call__\n",
            "    run_metadata_ptr)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFNDi4uEq5WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}